{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1ccf8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import matplotlib.image as mpimage\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.colors as c\n",
    "from torch import tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "616fff82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da1ad0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73b7d60",
   "metadata": {},
   "source": [
    "### Preprocessing Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a157785",
   "metadata": {},
   "source": [
    "#### Calculate Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d13693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper methods for preprocessing\n",
    "def calculate_weight(channels, depth, single_color, color_opponency, black_white):\n",
    "    weight_array = np.ones((channels, depth * 3, 1, 1))\n",
    "\n",
    "    if depth == 1:\n",
    "        if not single_color and not color_opponency and not black_white: # Average black-white image\n",
    "            weight_array[:, :3, :, :] *= 1 / 3\n",
    "        elif color_opponency and not single_color and not black_white: #color opponency depth 0\n",
    "            weight_array[0,:,:,:] = 1/3\n",
    "            for i in range(3):\n",
    "                weight_array[1, i, 0, 0] = [0.5, -0.5, 0][i]\n",
    "                weight_array[2, i, 0, 0] = [-0.5 / 3, -0.5 / 3, 1 / 3][i]\n",
    "        elif black_white and not color_opponency and not single_color: # Luminance black-white image\n",
    "            print(\"black_white\")\n",
    "            weight_array[:, 0, :, :] *= 0.299\n",
    "            weight_array[:, 1, :, :] *= 0.587\n",
    "            weight_array[:, 2, :, :] *= 0.114\n",
    "    else:\n",
    "        weight_array[:, :3, :, :] *= 1 / 3\n",
    "        weight_array[:, 3:, :, :] *= -(1 / (depth * 3 - 3))\n",
    "\n",
    "        if channels == 3 and single_color:\n",
    "            print(\"single_color\")\n",
    "            for c in range(channels):\n",
    "                weight_array[c, :, 0, 0] = 0  # Setze alles auf 0\n",
    "                weight_array[c, c, 0, 0] = 1  # Setze die 1 an die richtige Stelle\n",
    "\n",
    "                for i in range(1, depth):\n",
    "                    weight_array[c, i * 3 + c, 0, 0] = -1 / (depth - 1)\n",
    "\n",
    "        elif channels == 3 and color_opponency:\n",
    "            print(\"color_opponency\")\n",
    "            copy = weight_array[0, :, :, :]\n",
    "            weight_array = np.zeros((channels, depth * 3, 1, 1))\n",
    "            weight_array[0, :, :, :] = copy\n",
    "            base_r_g = [0.5, -0.5, 0]\n",
    "            r_g_value = [-(1 / ((depth - 1) * 2)), (1 / ((depth - 1) * 2)), 0]\n",
    "            base_b_y = [-0.5 / 3, -0.5 / 3, 1 / 3]\n",
    "            b_y_value = [(0.5 / (depth * 3 - 3)), (0.5 / (depth * 3 - 3)), -(1 / (depth * 3 - 3))]\n",
    "\n",
    "            for i in range(depth * 3):\n",
    "                if i < 3:\n",
    "                    # Setze die ersten drei Werte direkt auf 0.5, -0.5, 0\n",
    "                    weight_array[1, i, 0, 0] = base_r_g[i]\n",
    "                    weight_array[2, i, 0, 0] = base_b_y[i]\n",
    "                else:\n",
    "                    # FÃ¼lle den Rest mit dem Pattern entsprechend depth\n",
    "                    index = (i - 3) % 3\n",
    "                    weight_array[1, i, 0, 0] = r_g_value[index]\n",
    "                    weight_array[2, i, 0, 0] = b_y_value[index]\n",
    "\n",
    "\n",
    "\n",
    "    return weight_array\n",
    "\n",
    "def create_blur_kernel():\n",
    "    kernel = np.zeros((3, 3))\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            kernel[i, j] = 1 / 9\n",
    "\n",
    "    return kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadc87ce",
   "metadata": {},
   "source": [
    "#### Save Image Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00226106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image_co(image_tensor, where, save_name, channels, path, training):\n",
    "\n",
    "    if training:\n",
    "        savepath = path + \"/images\"\n",
    "    else:\n",
    "        savepath = path + \"/processed_images\"\n",
    "\n",
    "\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "\n",
    "    image_name = save_name\n",
    "    # Path(path + \"/\" + savepath +\"/\" + save_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cmap_R = c.LinearSegmentedColormap.from_list(\"cmap_R\",\n",
    "                                                 ['black', 'white'])  # hier sind die colormaps definiert,\n",
    "    cmap_G = c.LinearSegmentedColormap.from_list(\"cmap_G\", ['#0f0', 'white',\n",
    "                                                            '#f00'])  # in denen die channel angezeigt werden\n",
    "    cmap_B = c.LinearSegmentedColormap.from_list(\"cmap_B\", ['#00f', 'white',\n",
    "                                                            'yellow'])\n",
    "\n",
    "    boundary_red = max(torch.max(image_tensor[0]), -torch.min(image_tensor[0]))\n",
    "\n",
    "    f, axarr = plt.subplots(5, 4, figsize=(20, 20))\n",
    "\n",
    "    img_norm = (image_tensor - torch.min(image_tensor)) / (torch.max(image_tensor) - torch.min(image_tensor))\n",
    "    # img_norm = image_tensor / torch.max(image_tensor)\n",
    "    axarr[0][0].imshow(img_norm.detach().cpu().permute(1, 2, 0))\n",
    "    axarr[0][1].imshow(img_norm[0].detach().cpu(), cmap=cmap_R)\n",
    "    vutils.save_image(img_norm, \"\" + savepath + \"/\" + image_name + \"-CO.png\")\n",
    "    mpimage.imsave(\"\" + savepath + \"/\" + image_name + \"-bw.png\", img_norm[0].detach().cpu(), cmap=cmap_R,\n",
    "                   vmin=-boundary_red, vmax=boundary_red)\n",
    "\n",
    "    if channels > 1:\n",
    "        boundary_green = max(torch.max(image_tensor[1]), -torch.min(image_tensor[1]))\n",
    "        boundary_blue = max(torch.max(image_tensor[2]), -torch.min(image_tensor[2]))\n",
    "        axarr[0][2].imshow(img_norm[1].detach().cpu(), cmap=cmap_G)\n",
    "        axarr[0][3].imshow(img_norm[2].detach().cpu(), cmap=cmap_B)\n",
    "        mpimage.imsave(\"\" + savepath + \"/\" + image_name + \"-rg.png\", img_norm[1].detach().cpu(), cmap=cmap_G,\n",
    "                       vmin=-boundary_green, vmax=boundary_green)\n",
    "        mpimage.imsave(\"\" + savepath + \"/\" + image_name + \"-bg.png\", img_norm[2].detach().cpu(), cmap=cmap_B,\n",
    "                       vmin=-boundary_blue, vmax=boundary_blue)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def save_image_bw(image_tensor, where, save_name, channels, path, training):\n",
    "\n",
    "    if training:\n",
    "        savepath = path + \"/images\"\n",
    "    else:\n",
    "        savepath = path + \"/processed_images\"\n",
    "\n",
    "\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "\n",
    "    image_name = save_name\n",
    "    # Path(path + \"/\" + savepath +\"/\" + save_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cmap_R = c.LinearSegmentedColormap.from_list(\"cmap_R\",\n",
    "                                                 ['black', 'white'])  # hier sind die colormaps definiert, in denen die channel angezeigt werden\n",
    "\n",
    "\n",
    "    boundary_red = max(torch.max(image_tensor[0]), -torch.min(image_tensor[0]))\n",
    "\n",
    "    f, axarr = plt.subplots(5, 4, figsize=(20, 20))\n",
    "\n",
    "    img_norm = (image_tensor - torch.min(image_tensor)) / (torch.max(image_tensor) - torch.min(image_tensor))\n",
    "    # img_norm = image_tensor / torch.max(image_tensor)\n",
    "    axarr[0][0].imshow(img_norm.detach().cpu().permute(1, 2, 0))\n",
    "    axarr[0][1].imshow(img_norm[0].detach().cpu(), cmap=cmap_R)\n",
    "    vutils.save_image(img_norm, \"\" + savepath + \"/\" + image_name + \"-GRAY.png\")\n",
    "    mpimage.imsave(\"\" + savepath + \"/\" + image_name + \"-bw.png\", img_norm[0].detach().cpu(), cmap=cmap_R,\n",
    "                   vmin=-boundary_red, vmax=boundary_red)\n",
    "\n",
    "    if channels > 1:\n",
    "        boundary_green = max(torch.max(image_tensor[1]), -torch.min(image_tensor[1]))\n",
    "        boundary_blue = max(torch.max(image_tensor[2]), -torch.min(image_tensor[2]))\n",
    "        axarr[0][2].imshow(img_norm[1].detach().cpu(), cmap=cmap_R)\n",
    "        axarr[0][3].imshow(img_norm[2].detach().cpu(), cmap=cmap_R)\n",
    "        mpimage.imsave(\"\" + savepath + \"/\" + image_name + \"-rg.png\", img_norm[1].detach().cpu(), cmap=cmap_R,\n",
    "                       vmin=-boundary_green, vmax=boundary_green)\n",
    "        mpimage.imsave(\"\" + savepath + \"/\" + image_name + \"-bg.png\", img_norm[2].detach().cpu(), cmap=cmap_R,\n",
    "                       vmin=-boundary_blue, vmax=boundary_blue)\n",
    "\n",
    "    plt.close()\n",
    "\n",
    "def save_image_rgb(image_tensor, where, save_name, channels, path, training):\n",
    "\n",
    "    if training:\n",
    "        savepath = path + \"/images\"\n",
    "    else:\n",
    "        savepath = path + \"/processed_images\"\n",
    "\n",
    "\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "\n",
    "    image_name = save_name\n",
    "    # Path(path + \"/\" + savepath +\"/\" + save_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cmap_R = c.LinearSegmentedColormap.from_list(\"cmap_R\",\n",
    "                                                 ['black', 'white', '#f00'])  # hier sind die colormaps definiert,\n",
    "    cmap_G = c.LinearSegmentedColormap.from_list(\"cmap_G\", ['black', 'white',\n",
    "                                                            '#0f0'])  # in denen die channel angezeigt werden\n",
    "    cmap_B = c.LinearSegmentedColormap.from_list(\"cmap_B\", ['black', 'white', '#00f'])\n",
    "\n",
    "    boundary_red = max(torch.max(image_tensor[0]), -torch.min(image_tensor[0]))\n",
    "\n",
    "    f, axarr = plt.subplots(5, 4, figsize=(20, 20))\n",
    "\n",
    "    img_norm = (image_tensor - torch.min(image_tensor)) / (torch.max(image_tensor) - torch.min(image_tensor))\n",
    "    # img_norm = image_tensor / torch.max(image_tensor)\n",
    "    axarr[0][0].imshow(img_norm.detach().cpu().permute(1, 2, 0))\n",
    "    axarr[0][1].imshow(img_norm[0].detach().cpu(), cmap=cmap_R)\n",
    "    vutils.save_image(img_norm, \"\" + savepath + \"/\" + image_name + \"-RGB.png\")\n",
    "    mpimage.imsave(\"\" + savepath + \"/\" + image_name + \"-r.png\", img_norm[0].detach().cpu(), cmap=cmap_R,\n",
    "                   vmin=-boundary_red, vmax=boundary_red)\n",
    "\n",
    "    if channels > 1:\n",
    "        boundary_green = max(torch.max(image_tensor[1]), -torch.min(image_tensor[1]))\n",
    "        boundary_blue = max(torch.max(image_tensor[2]), -torch.min(image_tensor[2]))\n",
    "        axarr[0][2].imshow(img_norm[1].detach().cpu(), cmap=cmap_G)\n",
    "        axarr[0][3].imshow(img_norm[2].detach().cpu(), cmap=cmap_B)\n",
    "        mpimage.imsave(\"\" + savepath + \"/\" + image_name + \"-g.png\", img_norm[1].detach().cpu(), cmap=cmap_G,\n",
    "                       vmin=-boundary_green, vmax=boundary_green)\n",
    "        mpimage.imsave(\"\" + savepath + \"/\" + image_name + \"-b.png\", img_norm[2].detach().cpu(), cmap=cmap_B,\n",
    "                       vmin=-boundary_blue, vmax=boundary_blue)\n",
    "\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783ecf4c",
   "metadata": {},
   "source": [
    "#### Preprocessing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c8ea05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlurPreprocessing(nn.Module):\n",
    "    def __init__(self, blur_bool, blur_depth, single_color, color_opponency, channels, path, training, black_white):\n",
    "        super().__init__()\n",
    "        self.blur = blur_bool\n",
    "        self.num_images = blur_depth + 1\n",
    "        self.single_color = single_color\n",
    "        self.color_opponency = color_opponency\n",
    "        self.channels = channels\n",
    "        self.write = True\n",
    "        self.path = path\n",
    "        self.training = training\n",
    "        self.black_white = black_white\n",
    "\n",
    "        if self.blur:\n",
    "\n",
    "            blur_kernel = create_blur_kernel()\n",
    "            self.conv_blur = nn.Conv2d(3, 3 * self.num_images, 3, stride=(1, 1), padding=1, groups=3, bias=False)\n",
    "\n",
    "            self.conv_blur.weight = nn.Parameter(tensor(np.array([[blur_kernel],\n",
    "                                                                  [blur_kernel],\n",
    "                                                                  [blur_kernel]]), requires_grad=False).float())\n",
    "\n",
    "            for param in self.conv_blur.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            self.custom_layer = nn.Conv2d(self.num_images * 3, out_channels=channels, kernel_size=1,\n",
    "                                          stride=1, padding=0, bias=False)\n",
    "\n",
    "            weight_array = calculate_weight(self.channels, self.num_images, self.single_color, self.color_opponency, self.black_white)\n",
    "            self.custom_layer.weight = nn.Parameter(tensor(np.array(weight_array), requires_grad=True).float())\n",
    "\n",
    "\n",
    "            # freezing the preprocessing\n",
    "            for param in self.custom_layer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            self.change_channel_layer = nn.Conv2d(in_channels=1, out_channels=3, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "            print(\"preprocessing\")\n",
    "            print(self.conv_blur.weight)\n",
    "            print(self.custom_layer.weight)\n",
    "\n",
    "    def forward(self, x, save_name=\"image\"):\n",
    "        if self.blur:\n",
    "\n",
    "\n",
    "            concat_image = x\n",
    "\n",
    "            for i in range(self.num_images - 1):\n",
    "                x = self.conv_blur(x)\n",
    "                concat_image = torch.concat([concat_image, x], dim=1)\n",
    "\n",
    "            x = self.custom_layer(concat_image)\n",
    "\n",
    "            if self.channels == 1:\n",
    "                x = self.change_channel_layer(x)\n",
    "\n",
    "\n",
    "        if self.write:\n",
    "            if(save_name==\"image\"):\n",
    "                if(self.color_opponency):\n",
    "                    save_name = \"color_opponency\"\n",
    "                if self.single_color:\n",
    "                    save_name = \"single_color\"\n",
    "                if self.black_white:\n",
    "                    save_name = \"black_white\"\n",
    "            \n",
    "            if(self.color_opponency):\n",
    "                print(\"saving image after preprocessing\")\n",
    "                save_image_co(x[0], \"result\", save_name, self.channels, self.path, self.training)\n",
    "            if self.single_color:\n",
    "                print(\"saving image after preprocessing\")\n",
    "                save_image_rgb(x[0], \"result\", save_name, self.channels, self.path, self.training)\n",
    "            if self.black_white:\n",
    "                print(\"saving image after preprocessing\")\n",
    "                save_image_bw(x[0], \"result\", save_name, self.channels, self.path, self.training)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17bc996a",
   "metadata": {},
   "source": [
    "### Image Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c942c027",
   "metadata": {},
   "source": [
    "##### BW Depth5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6baf4780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing\n",
      "Parameter containing:\n",
      "tensor([[[[0.1111, 0.1111, 0.1111],\n",
      "          [0.1111, 0.1111, 0.1111],\n",
      "          [0.1111, 0.1111, 0.1111]]],\n",
      "\n",
      "\n",
      "        [[[0.1111, 0.1111, 0.1111],\n",
      "          [0.1111, 0.1111, 0.1111],\n",
      "          [0.1111, 0.1111, 0.1111]]],\n",
      "\n",
      "\n",
      "        [[[0.1111, 0.1111, 0.1111],\n",
      "          [0.1111, 0.1111, 0.1111],\n",
      "          [0.1111, 0.1111, 0.1111]]]])\n",
      "Parameter containing:\n",
      "tensor([[[[ 0.3333]],\n",
      "\n",
      "         [[ 0.3333]],\n",
      "\n",
      "         [[ 0.3333]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3333]],\n",
      "\n",
      "         [[ 0.3333]],\n",
      "\n",
      "         [[ 0.3333]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]]],\n",
      "\n",
      "\n",
      "        [[[ 0.3333]],\n",
      "\n",
      "         [[ 0.3333]],\n",
      "\n",
      "         [[ 0.3333]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]],\n",
      "\n",
      "         [[-0.0667]]]])\n",
      "\n",
      "Processing acdc_fog-1 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing acdc_night-1 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing acdc_rain-1 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing acdc_snow-1 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing cityscapes-1 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing dark_zurich-1 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing acdc_fog-2 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing acdc_night-2 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing acdc_rain-2 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing acdc_snow-2 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing cityscapes-2 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing dark_zurich-2 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing acdc_fog-3 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing acdc_night-3 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing acdc_rain-3 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing acdc_snow-3 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing citycapes-3 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing dark_zurich-3 ...\n",
      "saving image after preprocessing\n"
     ]
    }
   ],
   "source": [
    "\n",
    "blur_module = BlurPreprocessing(\n",
    "    blur_bool=True,\n",
    "    blur_depth=5,\n",
    "    single_color=False,\n",
    "    color_opponency=False,\n",
    "    channels=3,   # 1 or 3\n",
    "    path=\"Processed-Images/bw\",\n",
    "    training=False,\n",
    "    black_white=True\n",
    ")\n",
    "\n",
    "# Transform for images\n",
    "transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "for i in range(1,4):\n",
    "    # Get all images in ./images\n",
    "    image_files = glob.glob(\"./slices/\" + str(i) + \"/*.*\")\n",
    "\n",
    "    for img_path in image_files:\n",
    "        base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "        print(f\"\\nProcessing {base} ...\")\n",
    "\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        x = transform(img).unsqueeze(0)  # (1,3,H,W)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            out = blur_module(x, save_name=base + \"_bw\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b15024e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visualization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
