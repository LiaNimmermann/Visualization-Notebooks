{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f3cff43-f854-4f40-899a-33ed8c15079a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#from mmseg.registry import MODELS\n",
    "import os\n",
    "import matplotlib.image as mpimage\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.colors as c\n",
    "from torch import tensor\n",
    "import sys\n",
    "# helper methods for preprocessing\n",
    "def calculate_weight(channels, depth, single_color, color_opponency, black_white):\n",
    "    weight_array = np.ones((channels, depth * 3, 1, 1))\n",
    "    print(\"depth\" + str(depth))\n",
    "    if depth == 1:\n",
    "\n",
    "        print(\"sc\")\n",
    "        print(single_color)\n",
    "        print(\"bw\")\n",
    "        print(black_white)\n",
    "        \n",
    "        if not single_color and not color_opponency and not black_white: # Average black-white image\n",
    "            weight_array[:, :3, :, :] *= 1 / 3\n",
    "        elif color_opponency and not single_color and not black_white: #color opponency depth 0\n",
    "            print(\"color_opponency\")\n",
    "            copy = weight_array[0, :, :, :]\n",
    "            weight_array = np.zeros((channels, depth * 3, 1, 1))\n",
    "            weight_array[0, :, :, :] = copy\n",
    "            base_r_g = [0.5, -0.5, 0]\n",
    "            #r_g_value = [-(1 / ((depth - 1) * 2)), (1 / ((depth - 1) * 2)), 0]\n",
    "            base_b_y = [-0.5 / 3, -0.5 / 3, 1 / 3]\n",
    "            #b_y_value = [(0.5 / (depth * 3 - 3)), (0.5 / (depth * 3 - 3)), -(1 / (depth * 3 - 3))]\n",
    "\n",
    "            for i in range(depth * 3):\n",
    "                if i < 3:\n",
    "                    # Setze die ersten drei Werte direkt auf 0.5, -0.5, 0\n",
    "                    weight_array[1, i, 0, 0] = base_r_g[i]\n",
    "                    weight_array[2, i, 0, 0] = base_b_y[i]\n",
    "                #else:\n",
    "                    # Fülle den Rest mit dem Pattern entsprechend depth\n",
    "                #    index = (i - 3) % 3\n",
    "                #    weight_array[1, i, 0, 0] = r_g_value[index]\n",
    "                #    weight_array[2, i, 0, 0] = b_y_value[index]\n",
    "            weight_array[0,:,:,:] = 1/3\n",
    "\n",
    "            \n",
    "            print(\"HERE\")\n",
    "            #for i in range(1,3):\n",
    "             #   weight_array[1, i, 0, 0] = [0.5, -0.5, 0][i]\n",
    "              #  weight_array[2, i, 0, 0] = [-0.5 / 3, -0.5 / 3, 1 / 3][i]\n",
    "        elif black_white and not color_opponency and not single_color: # Luminance black-white image\n",
    "            print(\"black_white\")\n",
    "            weight_array[:, 0, :, :] *= 0.299\n",
    "            weight_array[:, 1, :, :] *= 0.587\n",
    "            weight_array[:, 2, :, :] *= 0.114\n",
    "    else:\n",
    "        weight_array[:, :3, :, :] *= 1 / 3\n",
    "        weight_array[:, 3:, :, :] *= -(1 / (depth * 3 - 3))\n",
    "\n",
    "        if channels == 3 and single_color:\n",
    "            print(\"single_color\")\n",
    "            for c in range(channels):\n",
    "                weight_array[c, :, 0, 0] = 0  # Setze alles auf 0\n",
    "                weight_array[c, c, 0, 0] = 1  # Setze die 1 an die richtige Stelle\n",
    "\n",
    "                for i in range(1, depth):\n",
    "                    weight_array[c, i * 3 + c, 0, 0] = -1 / (depth - 1)\n",
    "\n",
    "        elif channels == 3 and color_opponency:\n",
    "            print(\"color_opponency\")\n",
    "            copy = weight_array[0, :, :, :]\n",
    "            weight_array = np.zeros((channels, depth * 3, 1, 1))\n",
    "            weight_array[0, :, :, :] = copy\n",
    "            base_r_g = [0.5, -0.5, 0]\n",
    "            r_g_value = [-(1 / ((depth - 1) * 2)), (1 / ((depth - 1) * 2)), 0]\n",
    "            base_b_y = [-0.5 / 3, -0.5 / 3, 1 / 3]\n",
    "            b_y_value = [(0.5 / (depth * 3 - 3)), (0.5 / (depth * 3 - 3)), -(1 / (depth * 3 - 3))]\n",
    "\n",
    "            for i in range(depth * 3):\n",
    "                if i < 3:\n",
    "                    # Setze die ersten drei Werte direkt auf 0.5, -0.5, 0\n",
    "                    weight_array[1, i, 0, 0] = base_r_g[i]\n",
    "                    weight_array[2, i, 0, 0] = base_b_y[i]\n",
    "                else:\n",
    "                    # Fülle den Rest mit dem Pattern entsprechend depth\n",
    "                    index = (i - 3) % 3\n",
    "                    weight_array[1, i, 0, 0] = r_g_value[index]\n",
    "                    weight_array[2, i, 0, 0] = b_y_value[index]\n",
    "\n",
    "\n",
    "    print(weight_array)\n",
    "    return weight_array\n",
    "\n",
    "def create_blur_kernel():\n",
    "    kernel = np.zeros((3, 3))\n",
    "\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            kernel[i, j] = 1 / 9\n",
    "\n",
    "    return kernel\n",
    "\n",
    "def save_image(image_tensor, where, save_name, channels, path, training, sc, co, orig):\n",
    "\n",
    "    if training:\n",
    "        savepath = path + \"/images\"\n",
    "    else:\n",
    "        savepath = path + \"/images_test\"\n",
    "\n",
    "    savepath = path + \"/new_images\"\n",
    "    if sc:\n",
    "        savepath = savepath + \"/sc\"\n",
    "    if orig:    \n",
    "        savepath = savepath + \"/orig\"\n",
    "    if co:\n",
    "        savepath = savepath + \"/co\"\n",
    "    if (not sc and not co and not orig):\n",
    "        savepath = savepath + \"/bw\"\n",
    "\n",
    "\n",
    "    os.makedirs(savepath, exist_ok=True)\n",
    "    \n",
    "    image_name = save_name + \"_\" + where\n",
    "    # Path(path + \"/\" + savepath +\"/\" + save_name).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if sc:\n",
    "        cmap_R = c.LinearSegmentedColormap.from_list(\"cmap_R\",\n",
    "                                                 ['black', 'white', '#f00'])  # hier sind die colormaps definiert,\n",
    "        cmap_G = c.LinearSegmentedColormap.from_list(\"cmap_G\", ['black', 'white',\n",
    "                                                            '#0f0'])  # in denen die channel angezeigt werden\n",
    "        cmap_B = c.LinearSegmentedColormap.from_list(\"cmap_B\", ['black', 'white', '#00f'])\n",
    "    elif co:\n",
    "        cmap_R = c.LinearSegmentedColormap.from_list(\"cmap_R\",\n",
    "                                                 ['black', 'white', 'black'])  # hier sind die colormaps definiert,\n",
    "        cmap_G = c.LinearSegmentedColormap.from_list(\"cmap_G\", ['#0f0', 'white',\n",
    "                                                            '#f00'])  # in denen die channel angezeigt werden\n",
    "        cmap_B = c.LinearSegmentedColormap.from_list(\"cmap_B\", ['#ff0', 'white', '#00f'])   \n",
    "    elif orig:\n",
    "        cmap_R = c.LinearSegmentedColormap.from_list(\"cmap_R\",\n",
    "                                                 ['white', '#f00'])  # hier sind die colormaps definiert,\n",
    "        cmap_G = c.LinearSegmentedColormap.from_list(\"cmap_G\", ['white',\n",
    "                                                            '#0f0'])  # in denen die channel angezeigt werden\n",
    "        cmap_B = c.LinearSegmentedColormap.from_list(\"cmap_B\", ['white', '#00f'])\n",
    "    else:\n",
    "        cmap_R = c.LinearSegmentedColormap.from_list(\"cmap_R\",\n",
    "                                                 ['black', 'white', 'black'])  # hier sind die colormaps definiert,\n",
    "        cmap_G = c.LinearSegmentedColormap.from_list(\"cmap_G\", ['black', 'white',\n",
    "                                                            'black'])  # in denen die channel angezeigt werden\n",
    "        cmap_B = c.LinearSegmentedColormap.from_list(\"cmap_B\", ['black', 'white', 'black'])\n",
    "        \n",
    "    boundary_red = max(torch.max(image_tensor[0]), -torch.min(image_tensor[0]))\n",
    "    #f, axarr = plt.subplots(5, 4, figsize=(20, 20))\n",
    "    print(\"Red min:\")\n",
    "    print(torch.min(image_tensor[0]))\n",
    "    print(\"Red max:\")\n",
    "    print(torch.max(image_tensor[0]))\n",
    "    img_norm = (image_tensor - torch.min(image_tensor)) / (torch.max(image_tensor) - torch.min(image_tensor))\n",
    "    # img_norm = image_tensor / torch.max(image_tensor)\n",
    "    #axarr[0][0].imshow(img_norm.detach().cpu().permute(1, 2, 0))\n",
    "    #axarr[0][1].imshow(image_tensor[0].detach().cpu(), cmap=cmap_R)\n",
    "    #vutils.save_image(img_norm, \"\" + savepath + \"/\" + image_name + \"RGB.pdf\")\n",
    "    #plt.imsave(\"\" + savepath + \"/\" + image_name + \"-r.png\", image_tensor[0].detach().cpu(), cmap=cmap_R,\n",
    "                   #vmin=-boundary_red, vmax=boundary_red)\n",
    "     #               vmin=0, vmax=1)\n",
    "\n",
    "    if channels > 1:\n",
    "        boundary_green = max(torch.max(image_tensor[1]), -torch.min(image_tensor[1]))\n",
    "        boundary_blue = max(torch.max(image_tensor[2]), -torch.min(image_tensor[2]))\n",
    "        #axarr[0][2].imshow(image_tensor[1].detach().cpu(), cmap=cmap_G)\n",
    "        #axarr[0][3].imshow(image_tensor[2].detach().cpu(), cmap=cmap_B)\n",
    "        #plt.imsave(\"\" + savepath + \"/\" + image_name + \"-g.png\", image_tensor[1].detach().cpu(), cmap=cmap_G,\n",
    "                       #vmin=-boundary_green, vmax=boundary_green)\n",
    "         #               vmin=0, vmax=1)\n",
    "        plt.imsave(\"\" + savepath + \"/\" + image_name + \"-b.png\", image_tensor[2].detach().cpu(), cmap=cmap_B,\n",
    "                       vmin=-boundary_blue, vmax=boundary_blue)\n",
    "                       # vmin=0, vmax=1)\n",
    "\n",
    "    #plt.close()\n",
    "#@MODELS.register_module()\n",
    "class BlurPreprocessing(nn.Module):\n",
    "    def __init__(self, blur_bool, blur_depth, single_color, color_opponency, channels, path, training, black_white):\n",
    "        super().__init__()\n",
    "        self.blur = blur_bool\n",
    "        self.num_images = blur_depth + 1\n",
    "        self.single_color = single_color\n",
    "        self.color_opponency = color_opponency\n",
    "        self.channels = channels\n",
    "        self.write = True\n",
    "        self.path = path\n",
    "        self.training = training\n",
    "        self.black_white = black_white\n",
    "\n",
    "        #self.maxpool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        if self.blur:\n",
    "            blur_kernel = create_blur_kernel()\n",
    "            self.conv_blur = nn.Conv2d(\n",
    "                3, 3 * self.num_images, 3, stride=1, padding=1, groups=3, bias=False\n",
    "            )\n",
    "\n",
    "            self.conv_blur.weight = nn.Parameter(\n",
    "                tensor(np.array([[blur_kernel],\n",
    "                                 [blur_kernel],\n",
    "                                 [blur_kernel]]),\n",
    "                       requires_grad=False).float()\n",
    "            )\n",
    "\n",
    "            for param in self.conv_blur.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            self.custom_layer = nn.Conv2d(\n",
    "                self.num_images * 3, out_channels=channels, kernel_size=1,\n",
    "                stride=1, padding=0, bias=False\n",
    "            )\n",
    "\n",
    "            weight_array = calculate_weight(\n",
    "                self.channels, self.num_images, self.single_color,\n",
    "                self.color_opponency, self.black_white\n",
    "            )\n",
    "            self.custom_layer.weight = nn.Parameter(\n",
    "                tensor(np.array(weight_array), requires_grad=True).float()\n",
    "            )\n",
    "\n",
    "            # freeze preprocessing\n",
    "            for param in self.custom_layer.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "            self.change_channel_layer = nn.Conv2d(\n",
    "                in_channels=1, out_channels=3, kernel_size=1, stride=1, padding=0\n",
    "            )\n",
    "\n",
    "            print(\"preprocessing initialized\")\n",
    "\n",
    "    def forward(self, x, save_name=\"image\"):\n",
    "        #save_image(x[0], \"orig\", save_name, self.channels, self.path, self.training, self.single_color, self.color_opponency, True)\n",
    "        if self.blur:\n",
    "            if False:#self.write:\n",
    "                print(\"saving image before preprocessing\")\n",
    "                save_image(x[0], \"before\", save_name, self.channels, self.path, self.training)\n",
    "                np.save(f\"{save_name}_before.npy\", x[0].detach().cpu().numpy())\n",
    "\n",
    "            concat_image = x\n",
    "            for i in range(self.num_images - 1):\n",
    "                x = self.conv_blur(x)\n",
    "                concat_image = torch.concat([concat_image, x], dim=1)\n",
    "\n",
    "            x = self.custom_layer(concat_image)\n",
    "\n",
    "            if self.channels == 1:\n",
    "                x = self.change_channel_layer(x)\n",
    "\n",
    "        if self.write:\n",
    "            print(\"saving image after preprocessing\")\n",
    "            print(self.path)\n",
    "            print(self.channels)\n",
    "            print(save_name)\n",
    "            #pooled = self.maxpool(x[0])\n",
    "            save_image(x[0], \"after\", save_name, self.channels, self.path, self.training, self.single_color, self.color_opponency, False)\n",
    "\n",
    "            #save_image(pooled, \"processed-pooled\", save_name, self.channels, self.path, self.training, self.single_color, self.color_opponency, False)\n",
    "\n",
    "\n",
    "            \n",
    "            # save a copy as png (normalized)\n",
    "            output_img = x[0].detach().cpu().numpy()\n",
    "            \n",
    "            #output_img = np.transpose(output_img, (1, 2, 0))  # (H, W, C)\n",
    "\n",
    "            boundary = abs(output_img).max()\n",
    "           # normalize to 0-1 with 0->0.5\n",
    "            output_img = (output_img + boundary) / (boundary + boundary + 1e-8)\n",
    "            \n",
    "            # clip between 0.4 and 0.6\n",
    "            output_img = np.clip(output_img, 0.47, 0.53)\n",
    "            \n",
    "            # rescale clipped range to 0-1\n",
    "            output_img = (output_img - 0.47) / (0.53 - 0.47)\n",
    "            output_tensor = torch.tensor(output_img)\n",
    "            \n",
    "            #save_image(output_tensor, \"sig\", save_name, self.channels, self.path, self.training, self.single_color, self.color_opponency, False)\n",
    "            #imageio.imwrite(f\"{save_name}_after.png\", output_img)\n",
    "            # convert to 0-255 and uint8\n",
    "            output_img = (output_img * 255).astype(np.uint8)\n",
    "            \n",
    "            #norm_img = np.sqrt(norm_img)*255\n",
    "            #output_img = np.clip(norm_img*255, 0, 255).astype(np.uint8)\n",
    "            #imageio.imwrite(f\"{save_name}_after.pdf\", output_img)\n",
    "            \n",
    "            # disable further writing\n",
    "            #self.write = False\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b16d4ad-c3b4-4e4c-a5b0-d5fb182d3e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18f5214-c61e-4a95-85bf-0a8a53065470",
   "metadata": {},
   "source": [
    "## Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9018bb-c3fe-4e6d-bd5d-393da1ad0034",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing image_beforeRGB-1 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing image_before_acdc_fog_RGB-1 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing image_before_acdc_night_RGB-1 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing image_before_acdc_rain_RGB-1 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing image_before_acdc_snow_RGB-1 ...\n",
      "saving image after preprocessing\n",
      "\n",
      "Processing image_before_dark_zurich_RGB-1 ...\n",
      "saving image after preprocessing\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "from PIL import Image\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "\n",
    "blur_module = BlurPreprocessing(\n",
    "    blur_bool=False,\n",
    "    blur_depth=0,\n",
    "    single_color=False,\n",
    "    color_opponency=False,\n",
    "    channels=3,   # or 3\n",
    "    path=\".\",\n",
    "    training=False,\n",
    "    black_white=True\n",
    ")\n",
    "\n",
    "# Transform for images\n",
    "transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# Get all images in ./images\n",
    "image_files = glob.glob(\"./slices/1/*.*\")\n",
    "\n",
    "for img_path in image_files:\n",
    "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    print(f\"\\nProcessing {base} ...\")\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0)  # (1,3,H,W)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = blur_module(x, save_name=base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb08890c-79d5-4c8b-b0f7-8fd14eef59eb",
   "metadata": {},
   "source": [
    "## Grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "eeb0b87c-bdb0-4015-8c61-9f40dbc48862",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth6\n",
      "[[[[ 0.33333333]]\n",
      "\n",
      "  [[ 0.33333333]]\n",
      "\n",
      "  [[ 0.33333333]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]]\n",
      "\n",
      "\n",
      " [[[ 0.33333333]]\n",
      "\n",
      "  [[ 0.33333333]]\n",
      "\n",
      "  [[ 0.33333333]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]]\n",
      "\n",
      "\n",
      " [[[ 0.33333333]]\n",
      "\n",
      "  [[ 0.33333333]]\n",
      "\n",
      "  [[ 0.33333333]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]]]\n",
      "preprocessing initialized\n",
      "\n",
      "Processing image_beforeRGB-1_-1gray ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_beforeRGB-1_-1gray\n",
      "Red min:\n",
      "tensor(0.)\n",
      "Red max:\n",
      "tensor(1.0000)\n",
      "\n",
      "Processing image_before_acdc_fog_RGB-1_-1gray ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_fog_RGB-1_-1gray\n",
      "Red min:\n",
      "tensor(0.)\n",
      "Red max:\n",
      "tensor(1.0000)\n",
      "\n",
      "Processing image_before_acdc_night_RGB-1_-1gray ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_night_RGB-1_-1gray\n",
      "Red min:\n",
      "tensor(0.)\n",
      "Red max:\n",
      "tensor(1.0000)\n",
      "\n",
      "Processing image_before_acdc_rain_RGB-1_-1gray ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_rain_RGB-1_-1gray\n",
      "Red min:\n",
      "tensor(0.)\n",
      "Red max:\n",
      "tensor(1.0000)\n",
      "\n",
      "Processing image_before_acdc_snow_RGB-1_-1gray ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_snow_RGB-1_-1gray\n",
      "Red min:\n",
      "tensor(0.)\n",
      "Red max:\n",
      "tensor(1.0000)\n",
      "\n",
      "Processing image_before_dark_zurich_RGB-1_-1gray ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_dark_zurich_RGB-1_-1gray\n",
      "Red min:\n",
      "tensor(0.)\n",
      "Red max:\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "blur_module = BlurPreprocessing(\n",
    "    blur_bool=True,\n",
    "    blur_depth=5,\n",
    "    single_color=False,\n",
    "    color_opponency=False,\n",
    "    channels=3,   # or 3\n",
    "    path=\".\",\n",
    "    training=False,\n",
    "    black_white=True\n",
    ")\n",
    "\n",
    "# Transform for images\n",
    "transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# Get all images in ./images\n",
    "image_files = glob.glob(\"./slices/1/*.*\")\n",
    "\n",
    "for img_path in image_files:\n",
    "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    base = base + \"gray\"\n",
    "    print(f\"\\nProcessing {base} ...\")\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0)  # (1,3,H,W)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = blur_module(x, save_name=base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38fc5cbc-d8b6-4994-941e-f6accfcac23b",
   "metadata": {},
   "source": [
    "## Single Color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "494ed2a4-a3e9-4648-b167-0028ff805d55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth6\n",
      "single_color\n",
      "[[[[ 1. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]]\n",
      "\n",
      "\n",
      " [[[ 0. ]]\n",
      "\n",
      "  [[ 1. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]]\n",
      "\n",
      "\n",
      " [[[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 1. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[ 0. ]]\n",
      "\n",
      "  [[-0.2]]]]\n",
      "preprocessing initialized\n",
      "\n",
      "Processing image_beforeRGB-1_-1sc ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_beforeRGB-1_-1sc\n",
      "Red min:\n",
      "tensor(0.)\n",
      "Red max:\n",
      "tensor(1.0000)\n",
      "\n",
      "Processing image_before_acdc_fog_RGB-1_-1sc ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_fog_RGB-1_-1sc\n",
      "Red min:\n",
      "tensor(0.)\n",
      "Red max:\n",
      "tensor(1.0000)\n",
      "\n",
      "Processing image_before_acdc_night_RGB-1_-1sc ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_night_RGB-1_-1sc\n",
      "Red min:\n",
      "tensor(0.)\n",
      "Red max:\n",
      "tensor(1.0000)\n",
      "\n",
      "Processing image_before_acdc_rain_RGB-1_-1sc ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_rain_RGB-1_-1sc\n",
      "Red min:\n",
      "tensor(0.)\n",
      "Red max:\n",
      "tensor(1.0000)\n",
      "\n",
      "Processing image_before_acdc_snow_RGB-1_-1sc ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_snow_RGB-1_-1sc\n",
      "Red min:\n",
      "tensor(0.)\n",
      "Red max:\n",
      "tensor(1.0000)\n",
      "\n",
      "Processing image_before_dark_zurich_RGB-1_-1sc ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_dark_zurich_RGB-1_-1sc\n",
      "Red min:\n",
      "tensor(0.)\n",
      "Red max:\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "blur_module = BlurPreprocessing(\n",
    "    blur_bool=True,\n",
    "    blur_depth=5,\n",
    "    single_color=True,\n",
    "    color_opponency=False,\n",
    "    channels=3,   # or 3\n",
    "    path=\".\",\n",
    "    training=False,\n",
    "    black_white=True\n",
    ")\n",
    "\n",
    "# Transform for images\n",
    "transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# Get all images in ./images\n",
    "image_files = glob.glob(\"./slices/1/*.*\")\n",
    "\n",
    "for img_path in image_files:\n",
    "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    base = base + \"sc\"\n",
    "    print(f\"\\nProcessing {base} ...\")\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0)  # (1,3,H,W)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = blur_module(x, save_name=base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d789cf-d721-4e86-b490-e1786b13d53c",
   "metadata": {},
   "source": [
    "## Color opponency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2a57e40-177d-4dfc-882e-b2892ac272f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth6\n",
      "color_opponency\n",
      "[[[[ 0.33333333]]\n",
      "\n",
      "  [[ 0.33333333]]\n",
      "\n",
      "  [[ 0.33333333]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[-0.06666667]]]\n",
      "\n",
      "\n",
      " [[[ 0.5       ]]\n",
      "\n",
      "  [[-0.5       ]]\n",
      "\n",
      "  [[ 0.        ]]\n",
      "\n",
      "  [[-0.1       ]]\n",
      "\n",
      "  [[ 0.1       ]]\n",
      "\n",
      "  [[ 0.        ]]\n",
      "\n",
      "  [[-0.1       ]]\n",
      "\n",
      "  [[ 0.1       ]]\n",
      "\n",
      "  [[ 0.        ]]\n",
      "\n",
      "  [[-0.1       ]]\n",
      "\n",
      "  [[ 0.1       ]]\n",
      "\n",
      "  [[ 0.        ]]\n",
      "\n",
      "  [[-0.1       ]]\n",
      "\n",
      "  [[ 0.1       ]]\n",
      "\n",
      "  [[ 0.        ]]\n",
      "\n",
      "  [[-0.1       ]]\n",
      "\n",
      "  [[ 0.1       ]]\n",
      "\n",
      "  [[ 0.        ]]]\n",
      "\n",
      "\n",
      " [[[-0.16666667]]\n",
      "\n",
      "  [[-0.16666667]]\n",
      "\n",
      "  [[ 0.33333333]]\n",
      "\n",
      "  [[ 0.03333333]]\n",
      "\n",
      "  [[ 0.03333333]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[ 0.03333333]]\n",
      "\n",
      "  [[ 0.03333333]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[ 0.03333333]]\n",
      "\n",
      "  [[ 0.03333333]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[ 0.03333333]]\n",
      "\n",
      "  [[ 0.03333333]]\n",
      "\n",
      "  [[-0.06666667]]\n",
      "\n",
      "  [[ 0.03333333]]\n",
      "\n",
      "  [[ 0.03333333]]\n",
      "\n",
      "  [[-0.06666667]]]]\n",
      "preprocessing initialized\n",
      "\n",
      "Processing image_beforeRGB-1_-1co ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_beforeRGB-1_-1co\n",
      "Red min:\n",
      "tensor(-0.1378)\n",
      "Red max:\n",
      "tensor(0.5367)\n",
      "\n",
      "Processing image_before_acdc_fog_RGB-1_-1co ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_fog_RGB-1_-1co\n",
      "Red min:\n",
      "tensor(-0.2725)\n",
      "Red max:\n",
      "tensor(0.6068)\n",
      "\n",
      "Processing image_before_acdc_night_RGB-1_-1co ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_night_RGB-1_-1co\n",
      "Red min:\n",
      "tensor(-0.2830)\n",
      "Red max:\n",
      "tensor(0.4097)\n",
      "\n",
      "Processing image_before_acdc_rain_RGB-1_-1co ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_rain_RGB-1_-1co\n",
      "Red min:\n",
      "tensor(-0.2243)\n",
      "Red max:\n",
      "tensor(0.6260)\n",
      "\n",
      "Processing image_before_acdc_snow_RGB-1_-1co ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_snow_RGB-1_-1co\n",
      "Red min:\n",
      "tensor(-0.2102)\n",
      "Red max:\n",
      "tensor(0.6605)\n",
      "\n",
      "Processing image_before_dark_zurich_RGB-1_-1co ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_dark_zurich_RGB-1_-1co\n",
      "Red min:\n",
      "tensor(-0.2762)\n",
      "Red max:\n",
      "tensor(0.4254)\n"
     ]
    }
   ],
   "source": [
    "blur_module = BlurPreprocessing(\n",
    "    blur_bool=True,\n",
    "    blur_depth=5,\n",
    "    single_color=False,\n",
    "    color_opponency=True,\n",
    "    channels=3,   # or 3\n",
    "    path=\".\",\n",
    "    training=False,\n",
    "    black_white=True\n",
    ")\n",
    "\n",
    "# Transform for images\n",
    "transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# Get all images in ./images\n",
    "image_files = glob.glob(\"./slices/1/*.*\")\n",
    "\n",
    "for img_path in image_files:\n",
    "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    base = base + \"co\"\n",
    "    print(f\"\\nProcessing {base} ...\")\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0)  # (1,3,H,W)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = blur_module(x, save_name=base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f21b5-aa26-420c-8974-eee249cebca6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## CO D0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76978413-f8ef-45af-b87c-696ae591d2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depth1\n",
      "sc\n",
      "False\n",
      "bw\n",
      "False\n",
      "color_opponency\n",
      "HERE\n",
      "[[[[ 0.33333333]]\n",
      "\n",
      "  [[ 0.33333333]]\n",
      "\n",
      "  [[ 0.33333333]]]\n",
      "\n",
      "\n",
      " [[[ 0.5       ]]\n",
      "\n",
      "  [[-0.5       ]]\n",
      "\n",
      "  [[ 0.        ]]]\n",
      "\n",
      "\n",
      " [[[-0.16666667]]\n",
      "\n",
      "  [[-0.16666667]]\n",
      "\n",
      "  [[ 0.33333333]]]]\n",
      "preprocessing initialized\n",
      "\n",
      "Processing image_beforeRGB-1_-3co_d0 ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_beforeRGB-1_-3co_d0\n",
      "Red min:\n",
      "tensor(0.0824)\n",
      "Red max:\n",
      "tensor(0.9608)\n",
      "\n",
      "Processing image_before_acdc_fog_RGB-1_-3co_d0 ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_fog_RGB-1_-3co_d0\n",
      "Red min:\n",
      "tensor(0.0850)\n",
      "Red max:\n",
      "tensor(0.8601)\n",
      "\n",
      "Processing image_before_acdc_night_RGB-1_-3co_d0 ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_night_RGB-1_-3co_d0\n",
      "Red min:\n",
      "tensor(0.0275)\n",
      "Red max:\n",
      "tensor(0.9281)\n",
      "\n",
      "Processing image_before_acdc_rain_RGB-1_-3co_d0 ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_rain_RGB-1_-3co_d0\n",
      "Red min:\n",
      "tensor(0.0863)\n",
      "Red max:\n",
      "tensor(0.8915)\n",
      "\n",
      "Processing image_before_acdc_snow_RGB-1_-3co_d0 ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_acdc_snow_RGB-1_-3co_d0\n",
      "Red min:\n",
      "tensor(0.0745)\n",
      "Red max:\n",
      "tensor(0.9399)\n",
      "\n",
      "Processing image_before_dark_zurich_RGB-1_-3co_d0 ...\n",
      "saving image after preprocessing\n",
      ".\n",
      "3\n",
      "image_before_dark_zurich_RGB-1_-3co_d0\n",
      "Red min:\n",
      "tensor(0.0222)\n",
      "Red max:\n",
      "tensor(0.9569)\n"
     ]
    }
   ],
   "source": [
    "blur_module = BlurPreprocessing(\n",
    "    blur_bool=True,\n",
    "    blur_depth=0,\n",
    "    single_color=False,\n",
    "    color_opponency=True,\n",
    "    channels=3,   # or 3\n",
    "    path=\".\",\n",
    "    training=False,\n",
    "    black_white=False\n",
    ")\n",
    "\n",
    "# Transform for images\n",
    "transform = T.Compose([\n",
    "    T.ToTensor()\n",
    "])\n",
    "\n",
    "# Get all images in ./images\n",
    "image_files = glob.glob(\"./slices/3/*.*\")\n",
    "\n",
    "for img_path in image_files:\n",
    "    base = os.path.splitext(os.path.basename(img_path))[0]\n",
    "    base = base + \"co_d0\"\n",
    "    print(f\"\\nProcessing {base} ...\")\n",
    "\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    x = transform(img).unsqueeze(0)  # (1,3,H,W)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = blur_module(x, save_name=base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "235397eb-1a64-402e-87eb-eef93e12ab29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageOps\n",
    "\n",
    "# Open the PNG\n",
    "img = Image.open(\"new_images/co crop/image_beforeRGB-1co_d0_after-r.png\")\n",
    "\n",
    "# Invert (if it has alpha channel, handle it separately)\n",
    "if img.mode == 'RGBA':\n",
    "    r, g, b, a = img.split()\n",
    "    rgb = Image.merge(\"RGB\", (r, g, b))\n",
    "    inverted_rgb = ImageOps.invert(rgb)\n",
    "    inverted = Image.merge(\"RGBA\", (*inverted_rgb.split(), a))\n",
    "else:\n",
    "    inverted = ImageOps.invert(img)\n",
    "\n",
    "# Save result\n",
    "inverted.save(\"new_images/co crop/image_beforeRGB-1co_d0_after-r-i.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "17f30d37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved slices\\image_beforeRGB-1_-1.png ((1896, 2845))\n",
      "Saved slices\\image_beforeRGB-1_-2.png ((1896, 2845))\n",
      "Saved slices\\image_beforeRGB-1_-3.png ((1896, 2845))\n",
      "Saved slices\\image_before_acdc_fog_RGB-1_-1.png ((1778, 3000))\n",
      "Saved slices\\image_before_acdc_fog_RGB-1_-2.png ((1778, 3000))\n",
      "Saved slices\\image_before_acdc_fog_RGB-1_-3.png ((1778, 3000))\n",
      "Saved slices\\image_before_acdc_night_RGB-1_-1.png ((1778, 3000))\n",
      "Saved slices\\image_before_acdc_night_RGB-1_-2.png ((1778, 3000))\n",
      "Saved slices\\image_before_acdc_night_RGB-1_-3.png ((1778, 3000))\n",
      "Saved slices\\image_before_acdc_rain_RGB-1_-1.png ((1778, 3000))\n",
      "Saved slices\\image_before_acdc_rain_RGB-1_-2.png ((1778, 3000))\n",
      "Saved slices\\image_before_acdc_rain_RGB-1_-3.png ((1778, 3000))\n",
      "Saved slices\\image_before_acdc_snow_RGB-1_-1.png ((1778, 3000))\n",
      "Saved slices\\image_before_acdc_snow_RGB-1_-2.png ((1778, 3000))\n",
      "Saved slices\\image_before_acdc_snow_RGB-1_-3.png ((1778, 3000))\n",
      "Saved slices\\image_before_dark_zurich_RGB-1_-1.png ((1778, 3000))\n",
      "Saved slices\\image_before_dark_zurich_RGB-1_-2.png ((1778, 3000))\n",
      "Saved slices\\image_before_dark_zurich_RGB-1_-3.png ((1778, 3000))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "# Input and output directories\n",
    "input_dir = \"images\"      # your folder with input images\n",
    "output_dir = \"slices\"     # where to save results\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Loop over files\n",
    "for filename in os.listdir(input_dir):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        filepath = os.path.join(input_dir, filename)\n",
    "        img = Image.open(filepath)\n",
    "\n",
    "        width, height = img.size\n",
    "        slice_width = width // 3  # cut into 3 equal vertical parts\n",
    "\n",
    "        # Remove extension for naming\n",
    "        base, ext = os.path.splitext(filename)\n",
    "\n",
    "        for i in range(3):\n",
    "            left = i * slice_width\n",
    "            right = (i + 1) * slice_width\n",
    "            box = (left, 0, right, height)\n",
    "            slice_img = img.crop(box)\n",
    "\n",
    "            outname = f\"{base}_-{i+1}{ext}\"\n",
    "            outpath = os.path.join(output_dir, outname)\n",
    "            slice_img.save(outpath)\n",
    "\n",
    "            print(f\"Saved {outpath} ({slice_img.size})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bbc855",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "visualization",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
